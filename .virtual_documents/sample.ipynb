


!pip install shap
!pip install PyMuPDF
!pip show pandas scikit-learn PyMuPDF
import pandas as pd
import re
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import numpy as np
import shap





# --- 1. 데이터 준비 (시뮬레이션) ---

# (1) 사용자가 입력할 정보 (가상)
user_jeonse_price = 280000000  # 사용자가 계약할 전세금: 2억 8천만원

# (2) 등기부등본 PDF에서 텍스트를 추출했다고 가정하는 '가상 텍스트'
# 실제로는 PyMuPDF 라이브러리로 PDF 파일에서 이 텍스트를 읽어와야 합니다.
dummy_register_text = """
갑구 (소유권에 관한 사항)
1. 소유자 김민준 (880101-1******)
   주소 서울특별시 강남구 테헤란로 123
2. 소유권 이전 (2024.01.15)
3. 가압류 채권자: 우리카드, 청구금액: 5,000,000원

을구 (소유권 이외의 권리에 관한 사항)
1. 근저당권설정. 채권최고액 금 일억이천만원정(₩120,000,000). 채무자 김민준. 근저당권자 우리은행.
2. 근저당권설정. 채권최고액 금 오천만원정(₩50,000,000). 채무자 김민준. 근저당권자 국민은행.
"""

# (3) 국토교통부 API를 호출하여 매매가를 받았다고 가정하는 '가상 함수'
def get_market_price(address):
    """지정된 주소의 실거래가를 반환하는 가상 API 함수"""
    print(f"'{address}' 주소의 실거래가 조회 시뮬레이션...")
    return 350000000  # 가상 실거래 매매가: 3억 5천만원

# --- 2. 핵심 정보 추출 (정규표현식) ---
# 선순위 채권최고액 추출 (숫자만)
amounts = re.findall(r"채권최고액 .*?금 ([\d,]+)원", dummy_register_text.replace(",", ""))
senior_debt = sum([int(amount) for amount in amounts])

# 근저당권 및 압류/가압류 개수 카운트
mortgage_count = len(re.findall(r"근저당권설정", dummy_register_text))
seizure_count = len(re.findall(r"압류|가압류", dummy_register_text))

# 추출 결과 확인
print(f"총 선순위 채권최고액: {senior_debt:,}원")
print(f"근저당권 개수: {mortgage_count}개")
print(f"압류/가압류 개수: {seizure_count}개")
print("-" * 30)

# 가상 API 함수 호출
market_price = get_market_price("서울특별시 강남구 테헤란로 123")
print(f"조회된 매매가: {market_price:,}원")





# --- 3. 데이터프레임 생성 및 특성 계산 ---

# 추출한 정보와 API 정보를 합쳐서 데이터프레임을 만듭니다.
# 실제로는 여러 건의 데이터를 모아 DataFrame을 구성해야 합니다.
# 여기서는 시뮬레이션을 위해 여러 가상 데이터를 직접 생성합니다.

data = {
    '매매가': [350000000, 500000000, 200000000, 400000000, 600000000, 320000000],
    '전세금': [280000000, 450000000, 180000000, 300000000, 400000000, 250000000],
    '선순위채권': [170000000, 50000000, 20000000, 30000000, 400000000, 80000000],
    '압류개수': [1, 0, 0, 0, 1, 0]
}
df = pd.DataFrame(data)

# (1) 전세가율 계산
df['전세가율'] = (df['전세금'] / df['매매가']) * 100

# (2) 총 부채 비율 (전세금+선순위채권 / 매매가)
df['총부채비율'] = ((df['전세금'] + df['선순위채권']) / df['매매가']) * 100

print("---------- 생성된 특성 확인 ----------")
display(df)


# --- 4. 타겟 변수(Y) 생성 (위험 여부 라벨링) ---

# 위험 판단 규칙: 전세가율이 80%를 넘거나, 총부채비율이 100%를 넘거나, 압류가 1개 이상이면 '위험'
conditions = [
    (df['전세가율'] > 80),
    (df['총부채비율'] > 100),
    (df['압류개수'] >= 1)
]

# np.select를 사용하여 여러 조건 중 하나라도 만족하면 '위험(1)', 아니면 '안전(0)'으로 분류
df['위험여부'] = np.select(conditions, [1, 1, 1], default=0)


print("\n---------- 최종 학습 데이터셋 확인 ----------")
display(df)





# --- 5. 데이터 분리 및 모델 학습 ---

# (1) 특성(X)과 타겟(y) 분리
X = df[['전세가율', '총부채비율', '압류개수']] # 모델이 학습할 문제지
y = df['위험여부']                         # 모델이 맞춰야 할 정답

# (2) 학습 데이터와 테스트 데이터 분리 (80%는 학습, 20%는 테스트)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# (3) RandomForest 모델 초기화 및 학습
# n_estimators: 만들 나무의 개수, random_state: 재현성을 위한 시드값
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

print("모델 학습이 완료되었습니다.")
print(f"학습에 사용된 데이터 개수: {len(X_train)}개")
print(f"테스트에 사용될 데이터 개수: {len(X_test)}개")





# --- 6. 예측 및 성능 평가 ---

# (1) 테스트 데이터로 위험 여부 예측
y_pred = model.predict(X_test)

# (2) 예측 결과와 실제 정답 비교
print("---------- 모델 평가 결과 ----------")
print(f"정확도(Accuracy): {accuracy_score(y_test, y_pred):.2f}")
print("\n[ 혼동 행렬 (Confusion Matrix) ]")
# TN | FP
# ---|---
# FN | TP
print(confusion_matrix(y_test, y_pred))

print("\n[ 상세 평가 지표 (Classification Report) ]")
# precision: '위험'이라 예측한 것 중 진짜 '위험'의 비율
# recall: 실제 '위험' 매물 중 모델이 '위험'이라고 맞춘 비율 (가장 중요!)
print(classification_report(y_test, y_pred, zero_division=0))


# --- 7. 특성 중요도 확인 ---
# 어떤 특성이 위험도를 예측하는데 가장 큰 영향을 미쳤는지 확인
feature_importances = pd.Series(model.feature_importances_, index=X.columns)
feature_importances = feature_importances.sort_values(ascending=False)

print("\n---------- 특성 중요도 ----------")
print(feature_importances)





# !pip install shap
import shap

# --- 1. SHAP 값 계산 준비 ---
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_test)


# --- 2. 특정 예측 1건에 대한 시각화 및 확률 표시 ---
data_index_to_explain = 0

print(f"---------- [데이터 ID: {data_index_to_explain}] 예측 설명 ----------")
print("\n[선택된 데이터의 실제 값]")
print(X_test.iloc[data_index_to_explain])

# '위험(1)'일 확률을 계산합니다.
# predict_proba는 [[안전 확률, 위험 확률]] 형태의 배열을 반환하므로, [0, 1] 인덱스를 사용합니다.
risk_probability = model.predict_proba(X_test.iloc[[data_index_to_explain]])[0, 1]


print(f"\n실제 정답: {'위험' if y_test.iloc[data_index_to_explain] == 1 else '안전'}")
print(f"모델의 예측: 위험도 {risk_probability:.2%}") # 확률을 퍼센트로 포맷팅하여 출력


# --- 3. SHAP 시각화 ---
shap.initjs()
shap.force_plot(explainer.expected_value[1],
                shap_values[1][data_index_to_explain, :],
                X_test.iloc[data_index_to_explain, :])
